---
title: "Exploring historic data"
author: "Vanuatu National Statistics Office"
date: "`r format(Sys.Date(), '%d %b %Y')`"
output:
  html_document:
    toc: yes
    toc_depth: '2'
    toc_float: yes
params: 
  password: "ThisIsNotMyPassword"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r preparation, include=FALSE}

# Load the required libraries
library(RMySQL) # Interactiing with MySQL from R
library(knitr) # Nice tables
library(kableExtra) # Extra nice tables
library(basicPlotteR) # Progress bar
library(plotly) # Interactive graphs
library(openxlsx) # REad and write excel formatted files
library(RColorBrewer) # Creating colour pallettes
library(basicPlotteR) # Set transparency of colours

# Set the number of digits to use before using exp notation
options("scipen"=50)

# Load the general R functions
source("functions.R")

# Get the repository directory - for building relative paths
repository <- dirname(getwd())
```

# Introduction

Here we document the exploration of the historic trade statistics data for Vanuatu. Our aim is to understand how the value of different imported and exported commodities has changed through time. Due to the large nature of the historic data, these data are stored on a [MySQL](https://www.mysql.com/) server. We will use the [RMySQL](https://cran.r-project.org/web/packages/RMySQL/RMySQL.pdf) R package to interact with the local MySQL server from R.

To set up the local MySQL server, a dump of the VNSO server was shared and imported via the [MySQL Workbench](https://www.mysql.com/products/workbench/) on my computer. I had previously install MySQL by following these instructions:
- Installing on linux systems ([link](https://dev.mysql.com/doc/refman/8.0/en/linux-installation.html)), with extra help [here](https://itsfoss.com/install-mysql-ubuntu/).
- Installing on mac: ([link](https://dev.mysql.com/doc/mysql-osx-excerpt/5.7/en/osx-installation.html)), also, I think it comes ready installed! See [here](https://www.thoughtco.com/installing-mysql-on-mac-2693866))
- Installing on Windows ([link](https://dev.mysql.com/downloads/installer/)), with extra help [here](https://www.wikihow.com/Install-the-MySQL-Database-Server-on-Your-Windows-PC)

# Connecting to the database

The MySQL server is running locally and we can connect to it from R with the following code:

```{r connection, eval=FALSE}
# Open a connection to a MySQL database
connection <- dbConnect(MySQL(), 
                            user='JosephCrispell', 
                            password=readline(prompt="Enter password: "), # Doing this as password never stored in easily accessible format now
                            dbname='vnso',
                            host='localhost')
```


```{r echo=FALSE}
# Open a connection to a MySQL database
connection <- dbConnect(MySQL(), 
                        user='JosephCrispell', 
                        password=params$password, # Doing this as password never stored in easily accessible format now
                        dbname='vnso',
                        host='localhost')
```

```{r get size of tables, echo=FALSE}
nImportRecords <- dbGetQuery(conn=connection, statement="SELECT TABLE_ROWS FROM information_schema.TABLES WHERE table_name = 'historical_import_99_19'") # Slower more accurate query: SELECT COUNT(*) FROM historical_import_99_19
nExportRecords <- dbGetQuery(conn=connection, statement="SELECT TABLE_ROWS FROM information_schema.TABLES WHERE table_name = 'historical_export_99_19'") # Slower more accurate query: SELECT COUNT(*) FROM historical_export_99_19
```


On our local MySQL database there are two tables:

- `historical_export_99_19` - the historic data for all exports (~`r nExportRecords` rows)
- `historical_import_99_19` - the historic data for all imports (~`r nImportRecords` rows)

The imports data looks like this:

```{r quick look at historic imports data, echo=FALSE}

# Extract a small subset of historic data
historic_imports <- dbGetQuery(conn=connection, statement="SELECT * FROM historical_import_99_19 LIMIT 25")

# View the table
prettyTable(historic_imports)
```

<br>
And the exports data like this:
<br>

```{r quick look at historic exportsdata, echo=FALSE}

# Extract a small subset of historic data
historic_exports <- dbGetQuery(conn=connection, statement="SELECT * FROM historical_export_99_19 LIMIT 25")

# View the table
prettyTable(historic_exports)
```

# Summarise the `Value` distribution for each HS code

Each commodity in the historic data is identified by an 8 digit **HS** (Harmonized System) code. We are aiming to define the expected value distribution for each unique **HS** code through time for imports and exports. 

Firstly we need to calculate the unit value by dividing `Value` column by the `Weight` column for both the imports and exports:
```{r create column to store value divded by weight}
# Add column to correct Value column by Weight into IMPORTS table
colNames_imports <- dbGetQuery(connection, statement="SELECT COLUMN_NAME FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_SCHEMA='vnso' AND TABLE_NAME='historical_import_99_19'")
if("Value_corrected" %in% colNames_imports[, 1] == FALSE){
  dbSendQuery(connection, statement="ALTER TABLE historical_import_99_19 ADD Value_corrected DOUBLE AS (Value / Weight)")
}

# Add column to correct Value column by Weight into EXPORTS table
colNames_exports <- dbGetQuery(connection, statement="SELECT COLUMN_NAME FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_SCHEMA='vnso' AND TABLE_NAME='historical_export_99_19'")
if("Value_corrected" %in% colNames_exports[, 1] == FALSE){
  dbSendQuery(connection, statement="ALTER TABLE historical_export_99_19 ADD Value_corrected DOUBLE AS (Value / Weight)")
}
```

Using `MySQL` commands we can generate simple summary statistics of the `Value_corrected` column by HS code and year. For the exports, for example:

```{r summarise corrected value column}
# Summarise the corrected value column for each commodity for each year
commoditySummaryExports <- dbGetQuery(conn=connection, statement="SELECT HS, YEAR, Description, CTY_Dest AS CTY, AVG(Value_corrected) AS average, MAX(Value_corrected) AS maximum, MIN(Value_corrected) AS minimum, COUNT(Value_corrected) AS count, SUM(Value_corrected) AS sum, STDDEV_SAMP(Value_corrected) AS sd, VAR_SAMP(Value_corrected) as variance FROM historical_export_99_19 GROUP BY HS, YEAR")

# View the table
prettyTable(commoditySummaryExports[1:25, ])
```

Ideally though, we'd like to generate some additional summary statistics (like percentiles and median), particularly since the value of commodities is often highly skewed (with some rara items costing a huge amount). We can pull the import and export data into R to work with it directly:

```{r load all imports and exports}
# Get the historic data
exports <- dbGetQuery(conn=connection, statement="SELECT * FROM historical_export_99_19")
imports <- dbGetQuery(conn=connection, statement="SELECT * FROM historical_import_99_19")
```

```{r store local copy, echo=FALSE, eval=FALSE}
# Save the data as a standard csv
write.table(exports, file=file.path("..", "data", "secure", "tradeStats_historic_EXPORTS_14-09-20.csv"),
            sep=",", row.names=FALSE, quote=TRUE)
write.table(imports, file=file.path("..", "data", "secure", "tradeStats_historic_IMPORTS_14-09-20.csv"),
            sep=",", row.names=FALSE, quote=TRUE)
```

With these data loaded we'll use the following function:
```{r summary statistics function, eval=FALSE}
calculateSummaryStatistics <- function(values){
  
  # Create an output vector to store the summary statistics
  output <- c("Mean"=NA, "SD"=NA, "Median"=NA, "Lower-2.5"=NA, "Upper-97.5"=NA,
              "Min"=NA, "Max"=NA, "Count"=NA, "CountMissing"=NA)
  
  # Count number of values and any missing data
  output["Count"] <- length(values)
  output["CountMissing"] <- sum(is.na(values) | is.infinite(values) | is.nan(values))
  
  # Check if only missing available - if so stop and return empty summary statistics
  if(output["CountMissing"] == output["Count"]){
    return(output)
  }
  
  # Calculate mean
  output["Mean"] <- mean(values, na.rm=TRUE)
  
  # Calculate standard deviation
  output["SD"] <- sd(values, na.rm=TRUE)
  
  # Calculate median
  output["Median"] <- median(values, na.rm=TRUE)
  
  # Calculate upper and lower 95% percentile bounds
  quantiles <- quantile(values, probs=c(0.975, 0.025), na.rm=TRUE)
  output["Upper-97.5"] <- quantiles[1]
  output["Lower-2.5"] <- quantiles[2]
  
  # Calculate the range of the data
  minMax <- range(values, na.rm=TRUE)
  output["Min"] <- minMax[1]
  output["Max"] <- minMax[2]
  
  return(output)
}
```

With the function above we can use vector operations in R to quickly calculate summary statistics for both the import and export data:
```{r calculate summary statistics for imports and exports}
# Generate summary statistics for EXPORTS by HS code and year
exportsByHSCodeAndYear <- do.call(data.frame,
                                  aggregate(exports[, c("Value", "Value_corrected")], by=list(exports$HS, exports$Year),
                                            FUN=calculateSummaryStatistics))
colnames(exportsByHSCodeAndYear)[1:2] <- c("HS", "Year")

# Generate summary statistics for IMPORTS by HS code and year
importsByHSCodeAndYear <- do.call(data.frame,
                                  aggregate(imports[, c("Value", "Value_corrected")], by=list(imports$HS, imports$Year),
                                            FUN=calculateSummaryStatistics))
colnames(importsByHSCodeAndYear)[1:2] <- c("HS", "Year")
```


# Track trends in the principle imports and exports {.tabset}

The principle imports and exports are defined within the [`data/open/OPN_FINAL_ASY_PrincipleCommoditiesClassifications_31-01-20.xlsx`](https://github.com/Vanuatu-National-Statistics-Office/vnso-RAP-tradeStats-materials/blob/master/data/open/OPN_FINAL_ASY_PrincipleCommoditiesClassifications_31-01-20.xlsx) excel file. These define groups of **HS** codes that together represent the top imports and exports for Vanuatu. 

We can summarise the trends for these commodities and visualise their trends:

```{r read in the principle commodities table, echo=FALSE}

# Read in the principle commodities table
principle <- read.xlsx(file.path(repository, "data", "open", "OPN_FINAL_ASY_PrincipleCommoditiesClassifications_31-01-20.xlsx"))

# Merge the principle definitions into the commodity summary tables
commoditySummary <- merge(commoditySummary, principle, by.x="HS", by.y="HS.Code")
```

```{r calculate summary statistics for principle commodities, echo=FALSE}

# Note the exports of interest
exports <- unique(commoditySummary$PRINCIPAL.EXPORTS)
exports <- exports[exports != "OTHER PRODUCTS"]

# Note the imports of interest
imports <- unique(commoditySummary$PRINCIPAL.IMPORTS)
imports <- imports[is.na(imports) == FALSE]

# Get the range of years
years <- min(commoditySummary$YEAR):max(commoditySummary$YEAR)

# Build an initial table to store the summary statistics
principleCommoditySummary <- data.frame("Description"=NA, "Type"=NA, "Year"=NA,
                                        "Mean"=NA, "Variance"=NA, "StandardDeviation"=NA,
                                        stringsAsFactors=FALSE)
row <- 0

# Examine each year
for(year in years){

  # Examine each export
  for(description in exports){

    # Subset the summary statistics for commodities in current group
    groupStats <- commoditySummary[commoditySummary$PRINCIPAL.EXPORTS == description &
                                     commoditySummary$Type == "EXPORT" &
                                     commoditySummary$YEAR == year, ]
    
    # Calculate the combined summary statistics for current group
    combinedStats <- calculateCombineSummaryStatistics(means=groupStats$average,
                                                       sizes=groupStats$count,
                                                       variances=groupStats$variance)
    
    # Store the information
    row <- row + 1
    principleCommoditySummary[row, "Description"] <- description
    principleCommoditySummary[row, "Type"] <- "EXPORT"
    principleCommoditySummary[row, "Year"] <- year
    principleCommoditySummary[row, "Mean"] <- combinedStats["Mean"]
    principleCommoditySummary[row, "Variance"] <- combinedStats["Var"]
    principleCommoditySummary[row, "StandardDeviation"] <- combinedStats["SD"]
  }
  
    # Examine each imports
  for(description in imports){

    # Subset the summary statistics for commodities in current group
    groupStats <- commoditySummary[commoditySummary$PRINCIPAL.IMPORTS == description &
                                     commoditySummary$Type == "IMPORT" &
                                     commoditySummary$YEAR == year, ]
    
    # Calculate the combined summary statistics for current group
    combinedStats <- calculateCombineSummaryStatistics(means=groupStats$average,
                                                       sizes=groupStats$count,
                                                       variances=groupStats$variance)
    
    # Store the information
    row <- row + 1
    principleCommoditySummary[row, "Description"] <- description
    principleCommoditySummary[row, "Type"] <- "IMPORT"
    principleCommoditySummary[row, "Year"] <- year
    principleCommoditySummary[row, "Mean"] <- combinedStats["Mean"]
    principleCommoditySummary[row, "Variance"] <- combinedStats["Var"]
    principleCommoditySummary[row, "StandardDeviation"] <- combinedStats["SD"]
  }
}
```

## Trends in principle exports

```{r visualise principle commodity exports trends, echo=FALSE}
# Extract the export and import datasets
principleExportSummary <- principleCommoditySummary[principleCommoditySummary$Type == "EXPORT", ]
#principleImportSummary <- principleCommoditySummary[principleCommoditySummary$Type == "IMPORT", ]

# Products to highlight
exportsToHighlight <- c("BEEF", "COPRA", "COWHIDES")

# Start a plotly figure
fig <- plot_ly()

# Get the descriptions of principle commodities
descriptionsExports <- unique(principleExportSummary$Description)
descriptionsExportsShort <- substr(descriptionsExports, 1, 15)

# Define a colour for each principle commodity
palette <- colorRampPalette(brewer.pal(8, "Dark2"))
coloursExports <- palette(length(descriptionsExports)) 

# Add a trace for each principle commodity
for(index in seq_along(descriptionsExports)){
  
  # Get the data for current commodity
  summaryStats <- principleExportSummary[principleExportSummary$Description == descriptionsExports[index], ]
  
  # Remove rows with NAs
  summaryStates <- summaryStats[is.na(summaryStats$Mean) == FALSE, ]
  
  # Add a trace for current commodity
  labels <- paste("<b>Year</b>:", summaryStats$Year,
                  "<br>Mean: ", round(summaryStats$Mean, digits=0),
                  "<br>SD: ", round(summaryStats$StandardDeviation, digits=0),
                  "<br>Variance: ", round(summaryStats$Variance, digits=0))

  fig <- add_ribbons(fig, 
                     x=summaryStats$Year,
                     y=summaryStats$Mean,
                     ymin=summaryStats$Mean-summaryStats$StandardDeviation,
                     ymax=summaryStats$Mean+summaryStats$StandardDeviation,
                     name=descriptionsExportsShort[index], 
                     hovertemplate=labels,
                     line=list(color="transparent"),
                     fillcolor=setAlpha(coloursExports[index], 0.5),
                     visible=ifelse(descriptionsExports[index] %in% exportsToHighlight, TRUE, "legendonly"))
}

# Set initial plot title
fig <- layout(fig, title="Trends in unit value of principle commodities (<b>EXPORTS</b>)")

# Add initial X axis label
fig <- layout(fig, xaxis=list(title="Date"))

# Set Y axis to logged and label
fig <- layout(fig, yaxis=list(type="log", tickformat="f", title="Average unit value"))

fig

```

## Trends in principle imports
```{r plot trends for pinciple imports, echo=FALSE}
# Extract the export and import datasets
principleImportSummary <- principleCommoditySummary[principleCommoditySummary$Type == "IMPORT", ]
#principleImportSummary <- principleCommoditySummary[principleCommoditySummary$Type == "IMPORT", ]

# Products to highlight
importsToHighlight <- c("RICE", "Meat and edible offal of poultry")

# Start a plotly figure
fig <- plot_ly()

# Get the descriptions of principle commodities
descriptionsImports <- unique(principleImportSummary$Description)
descriptionsImportsShort <- substr(descriptionsImports, 1, 15)

# Define a colour for each principle commodity
palette <- colorRampPalette(brewer.pal(8, "Dark2"))
coloursImports <- palette(length(descriptionsImports)) 

# Add a trace for each principle commodity
for(index in seq_along(descriptionsImports)){
  
#index <- 1

  # Get the data for current commodity
  summaryStats <- principleImportSummary[principleImportSummary$Description == descriptionsImports[index], ]
  
  # Remove rows with NAs
  summaryStates <- summaryStats[is.na(summaryStats$Mean) == FALSE, ]
  
  # Add a trace for current commodity
  labels <- paste("<b>Year</b>:", summaryStats$Year,
                  "<br>Mean: ", round(summaryStats$Mean, digits=0),
                  "<br>SD: ", round(summaryStats$StandardDeviation, digits=0),
                  "<br>Variance: ", round(summaryStats$Variance, digits=0))
  fig <- add_ribbons(fig, 
                     x=summaryStats$Year,
                     y=summaryStats$Mean,
                     ymin=summaryStats$Mean-summaryStats$StandardDeviation,
                     ymax=summaryStats$Mean+summaryStats$StandardDeviation,
                     name=descriptionsImportsShort[index], 
                     hovertemplate=labels,
                     line=list(color="transparent"),
                     fillcolor=setAlpha(coloursImports[index], 0.5),
                     visible=ifelse(descriptionsImports[index] %in% importsToHighlight, TRUE, "legendonly"))
}

# Set initial plot title
fig <- layout(fig, title="Trends in unit value of principle commodities (<b>IMPORTS</b>)")

# Add initial X axis label
fig <- layout(fig, xaxis=list(title="Date"))

# Set Y axis to logged and label
fig <- layout(fig, yaxis=list(type="log", tickformat="f", title="Average unit value"))

fig

```

# Closing a connection to the `MySQL` server

To wrap up, we can close our connection to the `MySQL` server using the following code:
```{r warning=FALSE}
dbDisconnect(conn=connection)
```

